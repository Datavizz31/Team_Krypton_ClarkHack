# -*- coding: utf-8 -*-
"""Predicted_job_role.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RBctX-JAfeMtNLVgC6FpcKVi9MRx_5JL
"""

import pandas as pd
df = pd.read_csv('dataset.csv')
# drop first name last name full name
df.drop(['First_Name', 'Last_Name', 'Full_Name'], axis=1, inplace=True)
df.head()

#preparatory analysis
df.describe()
# Display column names and data types
print(df.dtypes)

y = df["Predicted_Job_Role"]  # Replace with actual target column
X = df.drop(columns=["Predicted_Job_Role"])  # Remove target from features

print(X.select_dtypes(include=['object']).columns)
# Perform One-Hot Encoding on all categorical columns
categorical_cols = X.select_dtypes(include=['object']).columns
X = pd.get_dummies(X, columns=categorical_cols, drop_first=True)

print("One-Hot Encoding Applied to All Categorical Columns!")
print(X.head())  # Verify the new columns

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)

from sklearn.model_selection import train_test_split

# Split into 80% training and 20% testing
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Confirm shapes
print("Training Set Shape:", X_train.shape)
print("Testing Set Shape:", X_test.shape)

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, classification_report

# Define models
log_reg = LogisticRegression()
rf = RandomForestClassifier(n_estimators=100, random_state=42)

# Function to train and evaluate a model
def train_and_evaluate(model, X_train, X_test, y_train, y_test, model_name):
    model.fit(X_train, y_train)  # Train model
    y_pred = model.predict(X_test)  # Predict on test data
    accuracy = accuracy_score(y_test, y_pred)  # Calculate accuracy

    print(f"ðŸ”¹ {model_name} Accuracy: {accuracy:.4f}")
    print(classification_report(y_test, y_pred))
    print("-" * 50)

# Train and evaluate all models
train_and_evaluate(log_reg, X_train, X_test, y_train, y_test, "Logistic Regression")
train_and_evaluate(rf, X_train, X_test, y_train, y_test, "Random Forest")

import pickle

# Save Logistic Regression model
with open("logistic_regression.pkl", "wb") as file:
    pickle.dump(log_reg, file)


print("Models saved successfully!")

from google.colab import files

uploaded = files.upload()  # This will prompt you to upload your .pkl file

!pip install streamlit
import streamlit as st
loaded_model = pickle.load(open("logistic_regression.pkl", "rb"))
st.title("Job Role Predictor")
st.write("Enter your details to predict the best job role for you.")

# User Inputs
gpa = st.number_input("Enter your GPA (0.0 - 4.0)", min_value=0.0, max_value=4.0, step=0.01)
major = st.selectbox("Select your Major", ["Computer Science", "Data Science", "Business", "Engineering", "Other"])
skills = st.text_area("Enter your Skills (comma-separated)")
courses = st.text_area("Enter Relevant Courses Taken (comma-separated)")
if st.button("Predict Job Role"):
    # Convert input into DataFrame format for prediction
    input_data = pd.DataFrame([[gpa, major, skills, courses]], columns=['GPA', 'Major', 'Skills', 'Courses'])
    prediction = model.predict(input_data)  # Ensure your model can handle categorical and text data

    st.success(f"Predicted Job Role: {prediction[0]}")

!echo "streamlit\npandas\nscikit-learn\nnumpy\LogisticRegression\RandomForestClassifier\XGBClassifier\accuracy_score, classification_report\StandardScaler\train_test_split" > requirements.txt

!jupyter nbconvert --to script /content/Predicted_Job_Role.ipynb

import os
print(os.listdir("/content"))